{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c76331b-9bc5-45bc-ab61-d05f17cc4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea5476f-9f07-46b6-8216-39bd4f712fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load neighborhood data from tiny_pdb_dir (25 random pdbs)\n",
    "\n",
    "filename = \"/gscratch/scrubbed/wgalvin/clean_clone/protein_holography-pytorch/protein_holography_pytorch/neighborhoods_tiny.hdf5\"\n",
    "\n",
    "max_atoms = 1000\n",
    "dt = np.dtype([\n",
    "    ('res_id','S6', (6)), # S5, 5 (old) ; S6, 6 (new with 2ndary structure)\n",
    "    ('atom_names', 'S4', (max_atoms)),\n",
    "    ('elements', 'S1', (max_atoms)),\n",
    "    ('res_ids', 'S6', (max_atoms, 6)), # S5, 5 (old) ; S6, 6 (new with 2ndary structure)\n",
    "    ('coords', 'f8', (max_atoms, 3)),\n",
    "    ('SASAs', 'f8', (max_atoms)),\n",
    "    ('charges', 'f8', (max_atoms)),\n",
    "])\n",
    "\n",
    "BACKBONE_ATOMS = [b' N  ', b' CA ', b' C  ', b' O  ']\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    data = np.unique(np.array(f['data'], dtype=dt), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f326de7-ff21-4906-8735-2cbd23f8a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_ids(neighborhood):\n",
    "    \"\"\"\n",
    "    Returns set of unique residue IDs\n",
    "    found in the res_ids field\n",
    "    \"\"\"\n",
    "    ids = set()\n",
    "    for item in neighborhood['res_ids']:\n",
    "        ids.add(id_to_str(item))\n",
    "    return ids\n",
    "\n",
    "def id_to_str(res_id):\n",
    "    \"\"\"\n",
    "    Converts a res_id to a string; 1 to 1\n",
    "    \"\"\"\n",
    "    return '_'.join([x.decode('utf-8') for x in res_id])\n",
    "\n",
    "def sample_ids(ids, p):\n",
    "    \"\"\"\n",
    "    Samples p proportion of list\n",
    "    \"\"\"\n",
    "    ids = list(ids)\n",
    "    random.shuffle(ids)\n",
    "    return [ids[i] for i in range(int(p * len(ids)))]\n",
    "\n",
    "def get_mask(res_ids, atom_names, ids, max_atoms):\n",
    "    \"\"\"\n",
    "    Returns a boolean mask of size (max_atoms) where\n",
    "    m[i] is True if corresponding res_id is in the list of \n",
    "    res_ids to keep\n",
    "    \"\"\"\n",
    "    mask = np.zeros((max_atoms), dtype=bool)\n",
    "    for i, (res_id, atom_name) in enumerate(zip(res_ids, atom_names)):\n",
    "        mask[i] = id_to_str(res_id) in ids or atom_name in BACKBONE_ATOMS\n",
    "    return mask\n",
    "\n",
    "\n",
    "def pad(arrays, max_atoms):\n",
    "    \"\"\"\n",
    "    Returns LIST of ndarrays padded to max_atoms\n",
    "    \"\"\"\n",
    "    return [pad_arr(arr, max_atoms) for arr in arrays];\n",
    "\n",
    "def pad_arr(arr, padded_length):\n",
    "    # get dtype of input array\n",
    "    dt = arr.dtype\n",
    "\n",
    "    # shape of sub arrays and first dimension (to be padded)\n",
    "    shape = arr.shape[1:]\n",
    "    orig_length = arr.shape[0]\n",
    "\n",
    "    # check that the padding is large enough to accomdate the data\n",
    "    if padded_length < orig_length:\n",
    "        print('Error: Padded length of {}'.format(padded_length),\n",
    "              'is smaller than original length of array {}'.format(orig_length))\n",
    "\n",
    "    # create padded array\n",
    "    padded_shape = (padded_length,*shape)\n",
    "    mat_arr = np.zeros(padded_shape, dtype=dt)\n",
    "\n",
    "    # add data to padded array\n",
    "    mat_arr[:orig_length] = np.array(arr)\n",
    "\n",
    "    return mat_arr\n",
    "\n",
    "def downsample(neighborhood, p, max_atoms=1000, remove_central=True):\n",
    "    \"\"\"\n",
    "    Takes a neighborhood, removes all but p proportion\n",
    "    of sidechains.\n",
    "    \n",
    "    Leaves backbone atoms in place. \n",
    "    \n",
    "    Returns a copy of the neighborhood modifies\n",
    "    \n",
    "    ```\n",
    "    # USAGE: \n",
    "    for neighborhood in data:\n",
    "        neighborhood = downsample(neighborhood, .5)\n",
    "        ...\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    # all ids\n",
    "    ids = get_res_ids(neighborhood)\n",
    "    \n",
    "    if remove_central:\n",
    "        ids.remove(id_to_str(neighborhood['res_id']))\n",
    "    \n",
    "    #ids to keep\n",
    "    ids = sample_ids(ids, p)\n",
    "    \n",
    "    mask = get_mask(neighborhood['res_ids'], neighborhood['atom_names'], ids, max_atoms)\n",
    "    \n",
    "    info = [neighborhood['res_id'], \n",
    "    neighborhood['atom_names'][mask],\n",
    "    neighborhood['elements'][mask],\n",
    "    neighborhood['res_ids'][mask],\n",
    "    neighborhood['coords'][mask],\n",
    "    neighborhood['SASAs'][mask],\n",
    "    neighborhood['charges'][mask]]\n",
    "    \n",
    "    info[1:] = pad(info[1:], max_atoms)\n",
    "    \n",
    "    x = np.zeros(shape=(1), dtype=dt)\n",
    "    x[0] = (*info, )\n",
    "    return x[0]\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cae3bd71ead04d2c6dfcead24d6901f0fb598c2e952e23069e9e0a4771248fdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
